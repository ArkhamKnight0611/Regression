{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Simple vs. Multiple Linear Regression\n",
        "Simple linear regression:\n",
        "\n",
        "Number of independent variables: 1\n",
        "Model: Dependent variable = Intercept + Slope * Independent variable\n",
        "Example: Predicting house price based on square footage\n",
        "Multiple linear regression:\n",
        "\n",
        "Number of independent variables: 2 or more\n",
        "Model: Dependent variable = Intercept + Slope1 * Independent variable1 + Slope2 * Independent variable2 + ...\n",
        "Example: Predicting student exam scores based on study hours, number of practice tests, and prior knowledge\n",
        "\n",
        "Q2. Assumptions of Linear Regression\n",
        "Linearity: Relationship between independent and dependent variables is linear.\n",
        "Homoscedasticity: Constant variance of errors across all levels of independent variables.\n",
        "Normality: Errors are normally distributed.\n",
        "Independence: Errors are independent of each other.\n",
        "No multicollinearity: Independent variables are not highly correlated with each other.\n",
        "Checking for assumptions:\n",
        "\n",
        "Visualize data: Scatter plots, residual plots.\n",
        "Statistical tests: Normality tests, homoscedasticity tests, multicollinearity diagnostics.\n",
        "\n",
        "Q3. Interpreting Slope and Intercept\n",
        "Slope: Represents the change in the dependent variable per unit change in the independent variable, holding other variables constant.\n",
        "Intercept: Represents the value of the dependent variable when all independent variables are equal to zero (may not be meaningful).\n",
        "Example: In the house price example, a slope of $100/sq ft means the price increases by $100 for every additional square foot, holding other factors like location constant. An intercept of $10,000 means a house with zero square footage would cost $10,000 (not realistic).\n",
        "\n",
        "Q4. Gradient Descent\n",
        "Concept: Iteratively adjusting model parameters (weights) to minimize the loss function (error between predicted and actual values).\n",
        "Machine learning: Used for training various models like linear regression, neural networks, etc. by minimizing the loss on training data.\n",
        "\n",
        "Q5. Multiple Linear Regression vs. Simple Linear Regression\n",
        "Key difference: Number of independent variables (1 vs. 2+).\n",
        "More complex: Multiple regression requires analyzing more variables and interactions, making interpretation more challenging.\n",
        "Potentially more accurate: Can explain phenomena more realistically by incorporating more factors.\n",
        "\n",
        "Q6. Multicollinearity\n",
        "Concept: High correlation between independent variables, causing instability in estimated coefficients and misleading interpretations.\n",
        "Detection: Variance Inflation Factor (VIF) analysis, correlation matrix examination.\n",
        "Addressing: Dropping collinear variables, using dimension reduction techniques, ridge regression.\n",
        "\n",
        "Q7. Polynomial Regression\n",
        "Concept: Introduces non-linearity by transforming independent variables into higher powers (e.g., squares, cubes) to capture curved relationships.\n",
        "Difference from linear regression: More flexible model that can fit non-linear patterns, but more complex and prone to overfitting.\n",
        "\n",
        "\n",
        "Q8. Advantages and Disadvantages of Polynomial Regression\n",
        "Advantages:\n",
        "\n",
        "Captures non-linear relationships.\n",
        "Useful for complex datasets.\n",
        "Disadvantages:\n",
        "\n",
        "Less interpretable coefficients.\n",
        "Prone to overfitting with increased polynomial degree.\n",
        "Increased computational cost.\n",
        "Use cases:\n",
        "\n",
        "When data clearly exhibits non-linearity.\n",
        "When capturing complex interactions is essential."
      ],
      "metadata": {
        "id": "tXFEATFxd2cM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ut8MHAekeS6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}