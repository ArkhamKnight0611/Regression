{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Elastic Net Regression and how does it differ from other regression techniques?\n",
        "\n",
        "Elastic Net Regression:\n",
        "\n",
        "Combines L1 (LASSO) and L2 regularization penalties, providing shrinkage and feature selection like LASSO while maintaining stability like Ridge regression.\n",
        "Shrinks coefficients towards zero, potentially setting some to zero for feature selection.\n",
        "Useful when features are highly correlated or noisy.\n",
        "Differences from Other Regression Techniques:\n",
        "\n",
        "Linear Regression: No regularization, susceptible to overfitting with many features.\n",
        "LASSO: Only uses L1 penalty, shrinks coefficients to zero for feature selection, but can be unstable with correlated features.\n",
        "Ridge Regression: Only uses L2 penalty, shrinks coefficients towards zero but doesn't select features, less prone to overfitting but doesn't offer as much sparsity.\n",
        "Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?\n",
        "\n",
        "Grid Search: Exhaustively evaluate combinations of alpha (L1 penalty) and l1_ratio (weight between L1 and L2 penalties) to find the combination that minimizes a cross-validation metric like mean squared error.\n",
        "Randomized Search: More efficient than grid search, explores parameter space randomly, often yields good results in less time.\n",
        "Bayesian Hyperparameter Optimization: Employs probabilistic methods to iteratively choose promising parameter values, can be computationally expensive but potentially more powerful.\n",
        "Q3. What are the advantages and disadvantages of Elastic Net Regression?\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Handles correlated features well.\n",
        "Performs feature selection.\n",
        "More robust than LASSO with correlated features.\n",
        "Disadvantages:\n",
        "\n",
        "Requires tuning multiple hyperparameters (alpha and l1_ratio).\n",
        "Interpretation of coefficients is less straightforward due to shrinkage.\n",
        "Q4. What are some common use cases for Elastic Net Regression?\n",
        "\n",
        "High-dimensional datasets with many features.\n",
        "Feature selection and model interpretability are important.\n",
        "Correlated features are present.\n",
        "Robustness to noise is desired.\n",
        "Q5. How do you interpret the coefficients in Elastic Net Regression?\n",
        "\n",
        "Coefficients are generally smaller than in unregularized regression due to shrinkage.\n",
        "Larger coefficients in magnitude indicate more important features.\n",
        "Coefficients cannot be directly compared across models with different alpha or l1_ratio values.\n",
        "Q6. How do you handle missing values when using Elastic Net Regression?\n",
        "\n",
        "Imputation: Fill in missing values with estimated values (e.g., mean, median, k-nearest neighbors).\n",
        "Deletion: Remove rows or columns with missing values (not recommended if many values are missing).\n",
        "Model Selection: Choose models that can automatically handle missing values (e.g., decision trees, random forests).\n",
        "Q7. How do you use Elastic Net Regression for feature selection?\n",
        "\n",
        "Coefficients close to zero are considered unimportant and can be removed.\n",
        "Use feature importance scoring methods like permutation importance or Shapley Additive exPlanations (SHAP).\n",
        "Be mindful of the trade-off between model performance and sparsity (number of features).\n",
        "Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?\n",
        "\n",
        "Pickling:\n",
        "\n",
        "Import pickle: import pickle\n",
        "Open a file in binary write mode: with open('model.pkl', 'wb') as f:\n",
        "Pickle the model: pickle.dump(model, f)\n",
        "Unpickling:\n",
        "\n",
        "Open the file in binary read mode: with open('model.pkl', 'rb') as f:\n",
        "Unpickle the model: model = pickle.load(f)\n",
        "Q9. What is the purpose of pickling a model in machine learning?\n",
        "\n",
        "Saves trained models to disk for reuse.\n",
        "Avoids retraining, saving time and computational resources.\n",
        "Enables sharing models with others.\n",
        "Useful for production deployment of models."
      ],
      "metadata": {
        "id": "PCyOouFpq5OI"
      }
    }
  ]
}